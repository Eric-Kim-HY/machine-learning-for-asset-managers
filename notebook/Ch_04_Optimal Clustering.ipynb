{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Asset Managers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4 Optimal Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snippet 4.1 Base Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterKMeansBase(corr0, maxNumClusters = 10, n_init = 10) :\n",
    "\n",
    "    x = ((1-corr0.fillna(0))/2)**0.5\n",
    "    silh = pd.Series()   # Observations matrix\n",
    "    \n",
    "    for init in range(n_init) :\n",
    "        for i in range (2, maxNumClusters +1) :\n",
    "            kmeans_ = KMeans(n_clusters = i, n_jobs=1, n_init=1)\n",
    "            kmeans_ = kmeans_.fit(x)\n",
    "            \n",
    "            silh_ = silhouette_samples(x, kmeans_.labels_)\n",
    "            stat = (silh_.mean() / silh_.std(), silh.mean/silh.std())\n",
    "            \n",
    "            if np.isnan(stat[1]) or stat[0] > stat[1] :\n",
    "                silh = silh_\n",
    "                kmeans = kmeans_\n",
    "    \n",
    "    # Reordering\n",
    "    newIdx = np.argsort(kmeans.labels_)\n",
    "    corr1 = corr0.iloc[newIdx] # reorder rows\n",
    "    corr1 = corr1.iloc[:, newIdx] # reorder columns\n",
    "    \n",
    "    clstrs = {i:corr0.columns[np.where(kmeans.labesl_==i)[0]].tolist() \\\n",
    "             for i in np.unique(kmeans.labels_)}  # cluster members\n",
    "    silh = pd.Series(silh, index = x.index)\n",
    "    \n",
    "    return corr1, clstrs, silh\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snippet 4.2 Top-Level of Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeNewOutputs(corr0, clstrs, clstrs2) :\n",
    "    \n",
    "    clstrsNew = {}\n",
    "    \n",
    "    # Allocate elements of cluster 1 and 2 to one dictionary (clstrsNew)\n",
    "    for key_i in clstrs.keys() :\n",
    "        clstrsNew[len(clstersNew.keys())] = list(clstrs[key_i])\n",
    "        \n",
    "    for key_j in clstrs2.keys() :\n",
    "        clstrsNew[len(clstersNew.keys())] = list(clstrs2[key_j])\n",
    "        \n",
    "    # need study\n",
    "    newIdx = [j for i in clstrsNew for j in clstrsNew[i]]\n",
    "    \n",
    "    # Rearrange the correlation matrix\n",
    "    corrNew = corr0.loc[newIdx, newIdx]\n",
    "    \n",
    "    # Correlation to distance\n",
    "    x = ((1 - corr0.fillna(0))/ 2.0) ** 0.5\n",
    "    \n",
    "    kmeans_labels = np.zeros(len(x.columns))\n",
    "    \n",
    "    # Get index using clstrsNew cluster and x's value\n",
    "    for idx in clstrsNew.keys() :\n",
    "        idxs = [x.index.get_loc(k) for k in clstrsNew[idx]]\n",
    "        \n",
    "    silhNew = pd.Series(silhouette_samples(x, kmeans_labels), index = x.index)\n",
    "    \n",
    "    return corrNew, clstrsNew, silhNew\n",
    "\n",
    "\n",
    "def clusterKMeansTop(corr0, maxNumClusters=None, n_init = 10) :\n",
    "    \n",
    "    # If there's no maxNumClusters value, set its value lenth(corr) - 1\n",
    "    if maxNumClusters == None :\n",
    "        maxNumClusters = corr0.shape[1] - 1 \n",
    "        \n",
    "    corr1, clstrs, silh = clusterKMeansBase(corr0, \n",
    "                                            maxNumClusters = min(maxNumClusters, corr0.shape[1] -1),\n",
    "                                            n_init = n_init)\n",
    "    \n",
    "    clustersTstats = {i:np.mean(silh[clstrs[i]])/ np.std(silh[clstrs[i]]) for i in clstrs.keys()}\n",
    "    \n",
    "    tStatMean = sum(clusterTstats.values()) / len(clusterTstats)\n",
    "    \n",
    "    redoClusters = [i for i in clusterTstats.keys() if clusterTstats[i] < tStatMean]\n",
    "    \n",
    "    if len(redoClusters) <= 1 :\n",
    "        return corr1, clstrs, silh\n",
    "    \n",
    "    else :\n",
    "        keysRedo = [j for i in redoClusters for j in clstrs[i]]\n",
    "        \n",
    "        corrTmp = corr0.loc[keysRedo, keysRedo]\n",
    "        tStatMean = np.mean([clusterTstats[i] for i in redoClusters])\n",
    "        \n",
    "        corr2, clstrs2, silh2 = clusterKMeansTop(corrTmp,\n",
    "                                                maxNumClusters = min(maxNumClusters, corrTmp.shape[1] -1),\n",
    "                                                n_init = n_init)\n",
    "        \n",
    "        # Make new outputs, if necessary\n",
    "        \n",
    "        corrNew, clstrsNew, silhNew = \\\n",
    "        makeNewOutputs(corr0,\n",
    "                       {i:clstrs[i] for i in clstrs.keys() if i not in redoClusters},\n",
    "                      clstrs2)\n",
    "        \n",
    "        newTstatMean = np.mean([np.mean(silhNew[clstrsNew[i]]) / np.std(silhNew[clstrsNew[i]]) for i in clstrsNew.keys()])\n",
    "        \n",
    "        if newTstatMean <= tStatMean :\n",
    "            return corr1, clstrs, silh\n",
    "        \n",
    "        else :\n",
    "            return corrNew, clstrsNew, silhNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snippet 4.3 Random Block Correlation Matrix Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import block_diag\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCovSub(nObs, nCols, sigma, random_state = None) :\n",
    "    \n",
    "    # Sub correl matrix\n",
    "    rng = check_random_state(random_state)\n",
    "    \n",
    "    if nCols == 1:\n",
    "        return np.ones((1,1))\n",
    "    \n",
    "    ar0 = rng.normal(size=(nObs, 1))\n",
    "    ar0 = np.repeat(ar0, nCols, axis =1 )\n",
    "    ar0 += rng.normal(scale=sigma, size = ar0.shape)\n",
    "    ar0 = np.cov(ar0, rowvar=False)\n",
    "    \n",
    "    return ar0\n",
    "\n",
    "\n",
    "def retRndBlockCov(nCols, nBlocks, minBlockSize=1, sigma = 1.0, random_state=None):\n",
    "    \n",
    "    # Generate a block random correlation matrix\n",
    "    rng = check_random_state(random_state)\n",
    "    parts = rng.choice(range(1, nCols - (minBlockSize -1) * nBlocks), nBlocks-1, replace=False)\n",
    "    parts.sort()\n",
    "    parts = np.append(parts, nCols - (minBlockSize - 1) * nBlocks)\n",
    "    parts = np.append(parts[0], np.diff(parts)) -1 + minBlockSize\n",
    "    \n",
    "    cov = None\n",
    "    \n",
    "    for nCols_ in parts :\n",
    "        cov_ = getCovSub(int(max(nCols_ * (nCols_ + 1)/2.0, 100)),\n",
    "                        nCols_,\n",
    "                        sigma,\n",
    "                        randome_state = rng)\n",
    "        \n",
    "        if cov is None :\n",
    "            cov = cov_copy()\n",
    "        else :\n",
    "            cov = block_diag(cov, cov_)\n",
    "            \n",
    "    return cov\n",
    "    \n",
    "\n",
    "\n",
    "def randomBlockCorr(nCols, nBlocks, random_state = None, minBlockSize=1) :\n",
    "        \n",
    "        \n",
    "    # Form block corr\n",
    "    rng = check_random_state(random_state)\n",
    "    \n",
    "    cov0 = getRndBlockCov(nCols, nBLocks,\n",
    "                         minBlockSize = minBlockSize,\n",
    "                         sigma = 0.5,\n",
    "                         random_state = rng)\n",
    "    \n",
    "    # Add Noise\n",
    "    cov1 = getRndBlockCov(nCols, 1,\n",
    "                         minBlockSize = minBlockSize,\n",
    "                         sigma = 1.0,\n",
    "                         random_state = rng)\n",
    "        \n",
    "    cov0 += cov1\n",
    "    \n",
    "    corr0 = cov2corr(cov0)\n",
    "    corr0 = pd.DataFrame(corr0)\n",
    "    \n",
    "    return corr0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO plot the graphs\n",
    "\n",
    "# TODO recall some functions (corr2cov etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py364",
   "language": "python",
   "name": "py364"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
